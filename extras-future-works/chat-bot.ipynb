{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0eabdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import pyttsx3\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier,_tree\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d91a0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('Training.csv')\n",
    "testing= pd.read_csv('Testing.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37123a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paraphraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c78507a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paraphraser import paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be494c6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mparaphrase\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI am having headache and also not feeling hungry than usual\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\paraphraser.py:13\u001b[0m, in \u001b[0;36mparaphrase\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     11\u001b[0m translated_sentence_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m language \u001b[38;5;129;01min\u001b[39;00m language_list:\n\u001b[1;32m---> 13\u001b[0m   text \u001b[38;5;241m=\u001b[39m \u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     14\u001b[0m   text \u001b[38;5;241m=\u001b[39m translator\u001b[38;5;241m.\u001b[39mtranslate(text\u001b[38;5;241m.\u001b[39mtext,src\u001b[38;5;241m=\u001b[39mlanguage,dest \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m   translated_sentence_list\u001b[38;5;241m.\u001b[39mappend(text\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\googletrans\\client.py:182\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[1;34m(self, text, dest, src, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    181\u001b[0m origin \u001b[38;5;241m=\u001b[39m text\n\u001b[1;32m--> 182\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# this code will be updated when the format is changed.\u001b[39;00m\n\u001b[0;32m    185\u001b[0m translated \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([d[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m d[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\googletrans\\client.py:78\u001b[0m, in \u001b[0;36mTranslator._translate\u001b[1;34m(self, text, dest, src, override)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_translate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, dest, src, override):\n\u001b[1;32m---> 78\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_acquirer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     params \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mbuild_params(query\u001b[38;5;241m=\u001b[39mtext, src\u001b[38;5;241m=\u001b[39msrc, dest\u001b[38;5;241m=\u001b[39mdest,\n\u001b[0;32m     80\u001b[0m                                 token\u001b[38;5;241m=\u001b[39mtoken, override\u001b[38;5;241m=\u001b[39moverride)\n\u001b[0;32m     82\u001b[0m     url \u001b[38;5;241m=\u001b[39m urls\u001b[38;5;241m.\u001b[39mTRANSLATE\u001b[38;5;241m.\u001b[39mformat(host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pick_service_url())\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\googletrans\\gtoken.py:194\u001b[0m, in \u001b[0;36mTokenAcquirer.do\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m     tk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macquire(text)\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tk\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\googletrans\\gtoken.py:62\u001b[0m, in \u001b[0;36mTokenAcquirer._update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# this will be the same as python code after stripping out a reserved word 'var'\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRE_TKK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvar \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# unescape special ascii characters such like a \\x3d(=)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m code \u001b[38;5;241m=\u001b[39m code\u001b[38;5;241m.\u001b[39mencode()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124municode-escape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "print(paraphrase(\"I am having headache and also not feeling hungry than usual\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b411ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7f6be08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "['runny nose', 'skin rash']\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def are_opposite(sentence1, sentence2):\n",
    "    sentiment1 = TextBlob(sentence1).sentiment.polarity\n",
    "    sentiment2 = TextBlob(sentence2).sentiment.polarity\n",
    "    return sentiment1 * sentiment2 < 0\n",
    "\n",
    "sentence1 = \"it's very hard to breathe and I am always feeling hungry. i am also having a little pain in chest\"\n",
    "sentence2 = \"I do not have excessive hunger\"\n",
    "\n",
    "print(are_opposite(sentence1, sentence2))\n",
    "\n",
    "text = \"I had runny nose 2 days ago and headaches with some cold and cough and skin rash and its hard to breathe and i am also having a little pain in chest\"\n",
    "blob = TextBlob(text)\n",
    "noun_phrases = blob.noun_phrases\n",
    "print(noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d7c5563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.4.1/en_core_web_md-3.4.1-py3-none-any.whl (42.8 MB)\n",
      "     ---------------------------------------- 42.8/42.8 MB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\python310\\lib\\site-packages (from en-core-web-md==3.4.1) (3.4.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.22.4)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (8.1.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.64.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.27.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.6.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.3)\n",
      "Requirement already satisfied: setuptools in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (58.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (21.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\python310\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.26.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\python310\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python310\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.1.1)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.4.1\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 23:34:50.488527: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2023-01-30 23:34:50.488568: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-30 23:34:54.375049: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2023-01-30 23:34:54.376221: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n",
      "2023-01-30 23:34:54.377225: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n",
      "2023-01-30 23:34:54.378463: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found\n",
      "2023-01-30 23:34:54.379603: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found\n",
      "2023-01-30 23:34:54.380946: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found\n",
      "2023-01-30 23:34:54.382600: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n",
      "2023-01-30 23:34:54.383767: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2023-01-30 23:34:54.383792: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a43ed0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7082442464704739\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "long_sentence = \"it's very hard to breathe and I am always feeling hungry. i am also having a little pain in chest\"\n",
    "given_phrase = \"I do have excessive hunger\"\n",
    "\n",
    "doc = nlp(long_sentence)\n",
    "doc2 = nlp(given_phrase)\n",
    "\n",
    "similarity = doc.similarity(doc2)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1927b217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     -------------------------------------- 86.0/86.0 kB 254.9 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 774.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from sentence-transformers) (4.64.0)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.13.1-cp310-cp310-win_amd64.whl (162.6 MB)\n",
      "     -------------------------------------- 162.6/162.6 MB 2.3 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (from sentence-transformers) (1.22.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\python310\\lib\\site-packages (from sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: scipy in c:\\python310\\lib\\site-packages (from sentence-transformers) (1.8.1)\n",
      "Requirement already satisfied: nltk in c:\\python310\\lib\\site-packages (from sentence-transformers) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 3.6 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
      "     -------------------------------------- 190.3/190.3 kB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.2.0)\n",
      "Requirement already satisfied: requests in c:\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp310-cp310-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\python310\\lib\\site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\python310\\lib\\site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\python310\\lib\\site-packages (from torchvision->sentence-transformers) (9.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python310\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.5.18.1)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=0409b50184b83ce1a396ae3f56bc5d140bc4623c509ad4f5f785019fb18a2385\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\0a\\f5\\dd\\9d00836c4e9e279c2a59d5b0ab72dafa66cbc626a327c550dd\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, torch, pyyaml, torchvision, huggingface-hub, transformers, sentence-transformers\n",
      "Successfully installed huggingface-hub-0.12.0 pyyaml-6.0 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 torch-1.13.1 torchvision-0.14.1 transformers-4.26.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2076f33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
